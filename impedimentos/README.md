# ğŸš§ Impedimentos e Aprendizados

Durante a configuraÃ§Ã£o e execuÃ§Ã£o do projeto, o ponto mais desafiador foi ajustar o arquivo **`docker-compose.yaml`**, responsÃ¡vel por definir toda a infraestrutura do **Airflow** â€” incluindo os serviÃ§os de **Webserver**, **Scheduler**, **Worker**, **Triggerer**, **Redis** e **PostgreSQL**.

Esse arquivo atua como o roteiro de inicializaÃ§Ã£o e integraÃ§Ã£o de todos os containers.  
Pequenas inconsistÃªncias na configuraÃ§Ã£o (como volumes, variÃ¡veis de ambiente ou dependÃªncias entre serviÃ§os) podem impedir o funcionamento correto do pipeline.

---

## ğŸ§© Problema principal â€” DAG presa em **`queued`**

Um dos maiores entraves foi entender por que a DAG permanecia no status **`queued`**, mesmo apÃ³s acionar manualmente o comando de trigger:

```bash
docker exec -it airflow-airflow-scheduler-1 bash -lc \
  "airflow dags trigger meteo_historico_nivel2 
```

Inicialmente, parecia um problema no **`worker`**, mas apÃ³s investigar os logs e processos ativos, identifiquei que o **`scheduler`** estava travado e nÃ£o processava as DAGs corretamente.
A soluÃ§Ã£o foi simples, mas sÃ³ clara depois de entender o papel de cada componente dentro da arquitetura:

```bash
docker restart airflow-airflow-scheduler-1
```

ApÃ³s o restart do scheduler, as DAGs passaram a ser executadas normalmente.
Esse aprendizado reforÃ§ou a importÃ¢ncia de **entender o funcionamento interno do Airflow e do Docker Compose**, nÃ£o apenas executar comandos isolados.

## ğŸ’¡ Outros aprendizados relevantes

- DiferenÃ§a entre **imagem** e **container** â€” entender que a imagem Ã© o modelo e o container Ã© a instÃ¢ncia viva em execuÃ§Ã£o;
- Correto mapeamento de **volumes** (./dags, ./logs, ./plugins) para persistÃªncia dos dados e cÃ³digos;
- O **scheduler** Ã© o coraÃ§Ã£o do Airflow â€” Ã© ele quem detecta, agenda e envia as tarefas para execuÃ§Ã£o;
- Uso dos comandos CLI (docker exec, docker logs, airflow dags list-runs, etc.) como parte da rotina de **observabilidade** e **debugging**.


---

## ğŸ§± 1ï¸âƒ£ O que Ã© um container

Um **container** Ã© uma **â€œcaixa isoladaâ€ que roda um serviÃ§o** â€” como se fosse um mini computador dentro do seu sistema, com:

- seu prÃ³prio sistema operacional (Linux leve),
- suas bibliotecas e dependÃªncias,
- e um processo principal (por exemplo, o **scheduler** do Airflow, ou o PostgreSQL).
- Ele nÃ£o Ã© uma pasta, e sim um ambiente em execuÃ§Ã£o â€” algo vivo, criado a partir de uma imagem.

Pensa assim:

**imagem** â†’ modelo congelado (como um bolo antes de assar)
**container** â†’ o bolo pronto, rodando no forno ğŸ°ğŸ”¥


## âš™ï¸ 2ï¸âƒ£ O papel do docker-compose.yaml

O arquivo docker-compose.yaml (ou .yml) Ã© um roteiro que define quais containers serÃ£o criados e como eles se conectam.

Exemplo simplificado (parte do seu):

```bash
services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow

  airflow-webserver:
    image: apache/airflow:2.10.4
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    volumes:
      - ./dags:/opt/airflow/dags
```

ğŸ’¬ Isso quer dizer:

- Crie um container chamado postgres usando a imagem postgres:13
- Crie outro container airflow-webserver
- Monte (espelhe) a pasta local ./dags dentro do container, em /opt/airflow/dags


Ã‰ o arquivo YAML (docker-compose.yml) que declara os serviÃ§os (webserver, scheduler, worker, postgres, redisâ€¦), as portas, volumes, variÃ¡veis de ambiente, etc. Ele Ã© o â€œmapaâ€ de como os containers (instÃ¢ncias de imagens Docker) sobem e conversam entre si.

**Imagem** = molde (a â€œfotoâ€ imutÃ¡vel com sistema + dependÃªncias).

**Container** = a instÃ¢ncia em execuÃ§Ã£o dessa imagem.

**Compose (YAML)** = orquestra o conjunto (quem sobe, portas, volumesâ€¦).

---

## ğŸ§­ 3ï¸âƒ£ Onde entra a pasta ~/airflow

A pasta ~/airflow Ã© sua pasta local, no seu computador (host).
Mas no docker-compose.yaml, vocÃª manda o Docker â€œespelharâ€ partes dela dentro dos containers, via o comando volumes:.

Por exemplo:

```bash
./dags:/opt/airflow/dags
```

significa:

Tudo que estÃ¡ na pasta local ```~/airflow/dags```
aparece dentro do container no caminho ```/opt/airflow/dags```

Ou seja:

- editar o cÃ³digo Python no seu computador â†’ reflete dentro do container automaticamente.
- mas o container nÃ£o Ã© a pasta â€” ele usa a pasta como parte do seu â€œdisco virtualâ€.

## ğŸ”© 4ï¸âƒ£ Cada container tem um papel no seu stack

No seu projeto Airflow:

| Container                    | FunÃ§Ã£o                 | Porta |
|-------------------------------|------------------------|-------|
| airflow-airflow-webserver-1   | Interface Web          | 8080  |
| airflow-airflow-scheduler-1   | Agenda e dispara DAGs  | â€”     |
| airflow-airflow-worker-1      | Executa tasks          | â€”     |
| airflow-postgres-1            | Banco de dados interno | 5432  |
| airflow-redis-1               | Fila de mensagens      | â€”     |
| airflow-flower-1              | Monitor Celery         | 5555  |


Esses containers se comunicam entre si (como se fossem mÃ¡quinas conectadas em rede local).
O Docker Compose gerencia todos eles em conjunto â€” o â€œmini clusterâ€ do Airflow.

## ğŸ§­ Resumo rÃ¡pido

| Termo | Significado |
|-------|--------------|
| **Imagem** | Modelo congelado (ex: apache/airflow:2.10.4) |
| **Container** | InstÃ¢ncia rodando da imagem |
| **docker-compose.yaml** | Roteiro que define quais containers e como se conectam |
| **Volume** | Espelho entre sua pasta local e o container |
| **Host** | Seu computador (onde o Docker estÃ¡ rodando) |
